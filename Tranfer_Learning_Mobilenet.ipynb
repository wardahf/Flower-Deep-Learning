{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d20c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f31ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using mobilenet it supports various input size, here i am using 128x128x3\n",
    "mobile_net=tf.keras.applications.MobileNet(input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model and Layers from tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,GlobalAveragePooling2D,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from global_average_pooling2d which is the flattening layer onwards are the dense layer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aced1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not including the Dense layer architecture in our base_model\n",
    "base_model=tf.keras.applications.MobileNet(input_shape=(128,128,3),include_top=False) #192,160,148,224 input shapes\n",
    "# for mobilenet\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86548f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the base modelsummary it is clear that flatten and dense layers are removed\n",
    "# we need to freeze trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781292f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False # deliberately making it False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all weights are now freezed as Trainable params are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now designing dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce524d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model architecture\n",
    "transfer_model=Sequential()\n",
    "transfer_model.add(base_model)# base model is added\n",
    "transfer_model.add(Flatten()) # increases weights and time consuming\n",
    "#transfer_model.add(GlobalAveragePooling2D())\n",
    "transfer_model.add(Dense(units=512,activation='relu'))\n",
    "transfer_model.add(Dropout(.2))\n",
    "transfer_model.add(Dense(units=64,activation='relu'))\n",
    "transfer_model.add(Dropout(.1))\n",
    "transfer_model.add(Dense(units=5,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing data are generated \n",
    "#in train data augmentation is also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d632aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n",
    "                  rotation_range=45,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2, # shrink\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,# becareful with flip dont flip numbers\n",
    "                  fill_mode='reflect'\n",
    "                   \n",
    "                  )\n",
    "test_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40712ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=train_datagen.flow_from_directory(\"C:\\\\Users\\\\warda\\\\flower_photos\\\\Training\",\n",
    "                                 target_size=(128,128),\n",
    "                                 batch_size=128,\n",
    "                                 class_mode='categorical') # for binary give class_mode=binary\n",
    "\n",
    "test_set=test_datagen.flow_from_directory(\"C:\\\\Users\\\\warda\\\\flower_photos\\\\Testing\",\n",
    "                                 target_size=(128,128),\n",
    "                                 batch_size=128,\n",
    "                                 class_mode='categorical')# images are taken in random way not sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797febf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "#using Adam as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks and earlystopping are used to store model weights of best model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=.01),\n",
    "ModelCheckpoint('C:\\\\Users\\\\warda\\\\Flowerbest_transfer',monitor='val_loss',save_best_only=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779906e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.fit(train_set,\n",
    "                      steps_per_epoch=2736//128, # how many times in one epoch weights need to be updated.\n",
    "                      epochs=5, # try 20\n",
    "                      validation_data=test_set,\n",
    "                      validation_steps=934//128,\n",
    "                  callbacks=keras_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35757dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9135a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=image.load_img('C:\\\\Users\\\\warda\\\\flower_photos\\\\example\\\\11.jpg',target_size=(128,128))\n",
    "\n",
    "\n",
    "test_img1=image.img_to_array(test_img)\n",
    "test_img1=tf.keras.applications.mobilenet.preprocess_input(test_img1)\n",
    "test_img2=np.expand_dims(test_img1,axis=0)\n",
    "# just one image for testing\n",
    "ypred=transfer_model.predict(test_img2)\n",
    "print(train_set.class_indices)\n",
    "print(\"The test image class is\",ypred.argmax())\n",
    "class_name=train_set.class_indices\n",
    "pos=np.array(list(class_name.values()))==ypred.argmax()\n",
    "name=np.array(list(class_name.keys()))\n",
    "print(\"The predicted class name is:\")\n",
    "print(name[pos][0])\n",
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90dc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "test_set=test_datagen.flow_from_directory('C:\\\\Users\\\\warda\\\\flower_photos\\\\Testing',\n",
    "                                 target_size=(128,128),\n",
    "                                 shuffle=False,\n",
    "                                 batch_size=1,     \n",
    "                                 class_mode='categorical') # binary for covid-noncovid(2 classes)\n",
    "\n",
    "filenames = test_set.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = transfer_model.predict_generator(test_set,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=predict.argmax(axis=1)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2cc1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yact=test_set.classes\n",
    "yact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sb\n",
    "plt.figure(figsize=(10,6))\n",
    "sb.heatmap(confusion_matrix(yact,ypred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with respect to tulip my model is not doing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74095d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remedy to change global avg pool to flatten and check it\n",
    "# resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tulips predicted as rose (29) class 4 has more wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yact,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16564ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  i want to know 27 wrong classifications as images \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yact1=pd.DataFrame(yact)\n",
    "ypred1=pd.DataFrame(ypred)\n",
    "\n",
    "y=pd.concat([yact1,ypred1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns=['yact','ypred']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40215d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[(y['yact']==4)&(y['ypred']==2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b7f1e",
   "metadata": {},
   "source": [
    "# Transfer Learning to Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.MobileNet(input_shape=(128,128,3),include_top=False) # here top is Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c836b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary() # load only convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d98f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.layers  # batch normalization is to scale data so data will converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of layers\n",
    "len(base_model.layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.layers[71:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:71]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "    # freezing the first 70 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing names if layers\n",
    "for layer in base_model.layers:\n",
    "    print(layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c22ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "transfer_model_t=Sequential()\n",
    "transfer_model_t.add(base_model)\n",
    "transfer_model_t.add(GlobalAveragePooling2D())\n",
    "transfer_model_t.add(Dense(units=512,activation='relu'))\n",
    "transfer_model_t.add(Dropout(.2))\n",
    "transfer_model_t.add(Dense(units=64,activation='relu'))\n",
    "transfer_model_t.add(Dropout(.1))\n",
    "transfer_model_t.add(Dense(units=5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n",
    "                  rotation_range=45,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2, # shrink\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,# becareful with flip dont flip numbers\n",
    "                  fill_mode='reflect'\n",
    "                   \n",
    "                  )\n",
    "test_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=train_datagen.flow_from_directory(\"C:\\\\Users\\\\warda\\\\flower_photos\\\\Training\",\n",
    "                                 target_size=(128,128),\n",
    "                                 batch_size=128,\n",
    "                                 class_mode='categorical') # for binary give class_mode=binary\n",
    "\n",
    "test_set=test_datagen.flow_from_directory(\"C:\\\\Users\\\\warda\\\\flower_photos\\\\Testing\",\n",
    "                                 target_size=(128,128),\n",
    "                                 batch_size=128,\n",
    "                                 class_mode='categorical')# images are taken in random way not sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Adam as optimizer\n",
    "ada=tf.keras.optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "transfer_model_t.compile(optimizer=ada(learning_rate=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=.01),\n",
    "ModelCheckpoint('C:\\\\Users\\\\warda\\\\Flowerbest_transfertt',monitor='val_loss',save_best_only=True)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd688093",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_t.fit(train_set,\n",
    "                      steps_per_epoch=2736//128, \n",
    "                      epochs=5, # try 20\n",
    "                      validation_data=test_set,\n",
    "                      validation_steps=934//128,\n",
    "                  callbacks=keras_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63015668",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_t.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "test_set=test_datagen.flow_from_directory('C:\\\\Users\\\\warda\\\\flower_photos\\\\Testing',\n",
    "                                 target_size=(128,128),\n",
    "                                 shuffle=False,\n",
    "                                 batch_size=1,     \n",
    "                                 class_mode='categorical') # binary for covid-noncovid(2 classes)\n",
    "\n",
    "filenames = test_set.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = transfer_model_t.predict_generator(test_set,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e02daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=predict.argmax(axis=1)\n",
    "yact=test_set.classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sb\n",
    "plt.figure(figsize=(10,6))\n",
    "sb.heatmap(confusion_matrix(yact,ypred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83283485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080bbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda40996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
